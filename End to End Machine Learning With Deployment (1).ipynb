{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682c94b9",
   "metadata": {},
   "source": [
    "# End to End Machine Learning with Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83707d0c",
   "metadata": {},
   "source": [
    "### Part1- EDA of Medical Dataset \n",
    "1. Import the libraries\n",
    "2. Load the data and view it\n",
    "3. Clean the data \n",
    "4. Perform EDA \n",
    "\n",
    "### Part2- Modelling of Dataset \n",
    "5. Preprocessing\n",
    "6. Fitting and Evaluation\n",
    "7. Optimization\n",
    "8. Interpretation\n",
    "9. Model Deploytment"
   ]
  },
  {
   "cell_type": "raw",
   "id": "494af570",
   "metadata": {},
   "source": [
    "!pip install xgboost --quiet"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1c6f7b0",
   "metadata": {},
   "source": [
    "!pip install streamlit --quiet\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "221e6955",
   "metadata": {},
   "source": [
    "!pip install imbalanced-learn --quiet"
   ]
  },
  {
   "cell_type": "raw",
   "id": "618990d4",
   "metadata": {},
   "source": [
    "!pip install xgboost --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cbcf33",
   "metadata": {},
   "source": [
    "### Step1: Import the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97438893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import warnings\n",
    "plt.style.use('fivethirtyeight')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# libraries for preprocessing \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# libraries for model fitting\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# libraries for model evaluation\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve\n",
    "\n",
    "print(\"All libraries are imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec7be7",
   "metadata": {},
   "source": [
    "### Step2:Load the data and view it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2843cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"data.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe3b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e386c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88475b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[~data.applymap(np.isreal).any(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553439f",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. The dataset has 768 rows and 10 columns\n",
    "2. The column 'Unnamed: 0' is redundant\n",
    "3. There are no nulls \n",
    "4. However there are 0's present as null which we have to take care of\n",
    "5. There are no corrupt characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc012f7",
   "metadata": {},
   "source": [
    "### Step3: Clean the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c7e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ccfa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerofiller=lambda x:x.replace(0, x.median())\n",
    "cols=data.columns[1:6]\n",
    "data[cols]=data[cols].apply(zerofiller, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fac631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the categorical outcome variable\n",
    "df=data.copy()\n",
    "d={\"Yes\":1, 'No':0}\n",
    "df['Outcome']=df['Outcome'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4093bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6840f9",
   "metadata": {},
   "source": [
    "### Step4: Perform EDA \n",
    "1. Univariates- NUmerical\n",
    "2. UNivariates- Categorical\n",
    "3. BUvariate - Categorical vs Numerical\n",
    "4. Bivariate - Numerical vs Numerical \n",
    "5. MUltivaraite Pairplot\n",
    "6. Correlations and Heatmpap\n",
    "7. Outcome is a binary categorical variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e5ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograms(df):\n",
    "    df.hist()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f572f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot(data, feature):\n",
    "    print(\"Bar plot of the variable \", feature)\n",
    "    plt.figure(figsize=(10,7))\n",
    "    ax=sns.countplot(data=data, x=feature, color='green')\n",
    "    for p in ax.patches:\n",
    "        x=p.get_bbox().get_points()[:,0]\n",
    "        y=p.get_bbox().get_points()[1,1]\n",
    "        ax.annotate(\"{:.2g}%\".format(100.*y/len(df)), (x.mean(), y), ha='center', va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot(df, 'Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_histplot(data, feature, bins=None, figsize=(12,7)):\n",
    "    print('Boxplot and Histplot for ', feature)\n",
    "    fig, (ax_box, ax_hist)=plt.subplots(\n",
    "    nrows=2,\n",
    "    sharex=True,\n",
    "    gridspec_kw = {\"height_ratios\":(0.25, 0.75)},\n",
    "    figsize=figsize\n",
    "    )\n",
    "    sns.boxplot(data=data, x=feature, color='violet', ax=ax_box, showmeans=True)\n",
    "    sns.histplotplot(data=data, x=feature, ax=ax_hist, bins=bins)   if bins else sns.histplot(data\\\n",
    "                            =data, x=feature, ax=ax_hist)  \n",
    "    ax_hist.axvline(data[feature].mean(), color='green', linestyle='--')\n",
    "    ax_hist.axvline(data[feature].median(), color='black', linestyle='-')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3631e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(exclude='O').columns:\n",
    "    boxplot_histplot(df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180424ff",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. We see that Pregnancies, Insulin, Dpf and Age are huighly right skewed\n",
    "2. Wee see that Outcome is highly imbalanced\n",
    "3. We see that skin thickness, insulin and Dpf have very high amount of outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20bb579",
   "metadata": {},
   "source": [
    "**Bivariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9aada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catnum(data, feature1, feature2):\n",
    "    print(\"The Bivariate barchart between {0} and {1}\".format(feature1, feature2))\n",
    "    data.groupby(feature1)[feature2].mean().plot(kind='bar', color='orange')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(exclude='O').columns:\n",
    "    catnum(df,'Outcome' ,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b618d5c7",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "The graphs show that women with higher no.of pregnancies, hiugher glucose level, higher insulin level , higher dpf and age are more likely tobe diabetic |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db900d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineplot_scatterplot(data, feature1, feature2):\n",
    "    plt.figure(figsize=(16,7))\n",
    "    print(\"Bivariates between {0} and {1}\".format(feature1, feature2))\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.lineplot(data=data, x=feature1, y=feature2, color='green')\n",
    "    plt.title('Lineplot')\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.scatterplot(data=data, x=feature1, y=feature2, color='blue')\n",
    "    plt.title('Scatterplot')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(exclude='O').columns:\n",
    "    lineplot_scatterplot(data=df,feature1='Age', feature2=col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe9849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb64703",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "There appears multicollinearity between Glucose and Insulin, BMI and skin thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050d52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at variables most correlated with Outcome \n",
    "df[df.columns[:]].corr()['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25fd5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "sns.heatmap(df.corr(), cmap='Spectral', vmax=+1, vmin=-1, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b930a",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "Glucose and BMI are the strongest predictors of Outcome "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e551e82a",
   "metadata": {},
   "source": [
    "Lets create an app top display these charts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3314fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile eda.py\n",
    "import streamlit as st\n",
    "st.title(\"The EDA Page\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "#load and clean the data\n",
    "data=pd.read_csv(\"data/data.csv\")\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "zerofiller=lambda x:x.replace(0, x.median())\n",
    "cols=data.columns[1:6]\n",
    "data[cols]=data[cols].apply(zerofiller, 0)\n",
    "# encode the categorical outcome variable\n",
    "df=data.copy()\n",
    "d={\"Yes\":1, 'No':0}\n",
    "df['Outcome']=df['Outcome'].map(d)\n",
    "def view_data(data):\n",
    "    st.write(df.head(10))\n",
    "    st.pyplot()\n",
    "\n",
    "def histograms(df):\n",
    "    df.hist()\n",
    "    plt.tight_layout()\n",
    "    st.pyplot()\n",
    "    \n",
    "def barplot(data, feature):\n",
    "    print(\"Bar plot of the variable \", feature)\n",
    "    plt.figure(figsize=(10,7))\n",
    "    ax=sns.countplot(data=data, x=feature, color='green')\n",
    "    for p in ax.patches:\n",
    "        x=p.get_bbox().get_points()[:,0]\n",
    "        y=p.get_bbox().get_points()[1,1]\n",
    "        ax.annotate(\"{:.2g}%\".format(100.*y/len(df)), (x.mean(), y), ha='center', va='bottom')\n",
    "    st.pyplot()\n",
    "    \n",
    "def boxplot_histplot(data, feature, bins=None, figsize=(12,7)):\n",
    "    print('Boxplot and Histplot for ', feature)\n",
    "    fig, (ax_box, ax_hist)=plt.subplots(\n",
    "    nrows=2,\n",
    "    sharex=True,\n",
    "    gridspec_kw = {\"height_ratios\":(0.25, 0.75)},\n",
    "    figsize=figsize\n",
    "    )\n",
    "    sns.boxplot(data=data, x=feature, color='violet', ax=ax_box, showmeans=True)\n",
    "    sns.histplotplot(data=data, x=feature, ax=ax_hist, bins=bins)   if bins else sns.histplot(data\\\n",
    "                            =data, x=feature, ax=ax_hist)  \n",
    "    ax_hist.axvline(data[feature].mean(), color='green', linestyle='--')\n",
    "    ax_hist.axvline(data[feature].median(), color='black', linestyle='-')\n",
    "    st.pyplot()\n",
    "    \n",
    "st.sidebar.subheader(\"Choose the Plot\")\n",
    "plot=st.sidebar.selectbox('plot', ('Data', 'Histograms', 'Barchart', 'Boxplot_Scatterplot', 'Correlations'))\n",
    "\n",
    "if st.sidebar.button('PLOT'):\n",
    "    if plot=='Data':\n",
    "        view_data(df)\n",
    "    if plot=='Histograms':\n",
    "        histograms(df)\n",
    "    if plot=='Barchart':\n",
    "        barplot(df, feature='Outcome')\n",
    "    if plot=='Boxplot_Scatterplot':\n",
    "        for col in df.select_dtypes(exclude='O').columns:\n",
    "            boxplot_histplot(df, col)\n",
    "    if plot=='Correlations':\n",
    "        plt.figure(figsize=(12,7))\n",
    "        sns.heatmap(df.corr(), cmap='Spectral', vmax=+1, vmin=-1, annot=True)\n",
    "        st.pyplot()\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef77deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faa5b7fd",
   "metadata": {},
   "source": [
    "### Step5: Preprocessing\n",
    "- separate features and label\n",
    "- impute nulls\n",
    "- encode categorical\n",
    "- solve for data imbalance\n",
    "- train test split\n",
    "- standard scaling only on the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f84d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to do the preprocessing \n",
    "\n",
    "def preprocess(data,label):\n",
    "    # separate the features and label\n",
    "    X=df.drop(label,axis=1)\n",
    "    y=df[label]\n",
    "    #solve for data imbalance\n",
    "    sm=SMOTE()\n",
    "    X,y=sm.fit_resample(X,y)\n",
    "    #train test split\n",
    "    x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=preprocess(df,\"Outcome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b437f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the features\n",
    "\n",
    "ss=StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d2fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a93eba6",
   "metadata": {},
   "source": [
    "**The data is ready for modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e4b987",
   "metadata": {},
   "source": [
    "### Step6: Fit and Evaluate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf34e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001126cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrix(y_test,y_pred,model_name):\n",
    "    print(\"Metrics for the model : \",model_name)\n",
    "    print(\"\\nAccuracy Score = \", accuracy_score(y_test,y_pred))\n",
    "    print(\"\\nPrecision Score = \", precision_score(y_test,y_pred))\n",
    "    print(\"\\nRecall Score = \", recall_score(y_test,y_pred))\n",
    "    print(\"\\nF1 Score = \", f1_score(y_test,y_pred))\n",
    "    print(\"\\nROC AUC Score = \", roc_auc_score(y_test,y_pred))\n",
    "    print(\"\\nClassification Report  \\n\\n\", classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(clf,x_test,y_test,model_name):\n",
    "    print(\"Metrics for the model : \",model_name)\n",
    "    plot_confusion_matrix(clf,x_test,y_test,display_labels=[0,1])\n",
    "    print('')\n",
    "    plot_roc_curve(clf,x_test,y_test)\n",
    "    print('')\n",
    "    plot_precision_recall_curve(clf,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15460269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and Evaluate the KNN model\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred=knn.predict(x_test)\n",
    "print_metrix(y_test,y_pred,knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e10e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(knn,x_test,y_test,\"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us tune the hyperparameters of knn\n",
    "\n",
    "neighbors = np.arange(1,12)\n",
    "train_accuracies = np.empty(len(neighbors))\n",
    "test_accuracies = np.empty(len(neighbors))\n",
    "\n",
    "for i,k in enumerate(neighbors):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train,y_train)\n",
    "    train_accuracies[i]=knn.score(x_train,y_train)\n",
    "    test_accuracies[i]=knn.score(x_test,y_test)\n",
    "    \n",
    "# plot the model complexity curve\n",
    "plt.title(\"Model Complexity Curves\")\n",
    "plt.plot(neighbors,train_accuracies,label=\"Train Accuracies\")\n",
    "plt.plot(neighbors,test_accuracies,label=\"Test Accuracies\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783744b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit knn with k=8\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred=knn.predict(x_test)\n",
    "print_metrix(y_test,y_pred,knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae487109",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lets fit all models at once and decide the one to optimize\n",
    "\n",
    "clfs = {\"Logistic Regression\":LogisticRegression(),\n",
    "      \"Decision Tree\":DecisionTreeClassifier(),\n",
    "      \"Random Forest\":RandomForestClassifier(),\n",
    "      \"KNN\":KNeighborsClassifier(),\n",
    "      \"Navies Bayes\":GaussianNB(),\n",
    "       \"Ada Boost\":AdaBoostClassifier(),\n",
    "       \"Gradient Boosting\":GradientBoostingClassifier(),\n",
    "       \"XGBoost\":XGBClassifier(),\n",
    "       \"SVM\":SVC()\n",
    "      }\n",
    "\n",
    "models_report=pd.DataFrame(columns=['Model Name',\"Accuracy\",\"Recall\",\"Precision\",\"F1 Score\"])\n",
    "\n",
    "for clf,clf_name in list(zip(clfs.values(),clfs.keys())):\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred=clf.predict(x_test)\n",
    "    print(\"Fitting the model ....\",clf_name)\n",
    "    t=pd.Series({'Model Name':clf_name,\n",
    "                 \"Accuracy\":accuracy_score(y_test,y_pred),\n",
    "                 \"Recall\":recall_score(y_test,y_pred),\n",
    "                 \"Precision\":precision_score(y_test,y_pred),\n",
    "                 \"F1 Score\":f1_score(y_test,y_pred)\n",
    "                })\n",
    "    \n",
    "    models_report=models_report.append(t,ignore_index=True)\n",
    "\n",
    "\n",
    "models_report=models_report.sort_values(by='F1 Score',ascending=False)\n",
    "models_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6736fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(x_train,y_train)\n",
    "y_pred=rfc.predict(x_test)\n",
    "print_metrix(y_test,y_pred,'Random Forest')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72d39c78",
   "metadata": {},
   "source": [
    "# Lets optimize Random Forest\n",
    "\n",
    "param_grid={\n",
    "    'n_estimators':[100,150,200],\n",
    "    'min_samples_leaf':range(1,5,1),\n",
    "    'min_samples_split':range(2,10,2),\n",
    "    'max_depth':[1,2,3,4,5],\n",
    "    'max_features':['sqrt','log2'],\n",
    "    'criterion':['gini','entropy']}\n",
    "\n",
    "n_folds=3\n",
    "cv=GridSearchCV(estimator=rfc,param_grid=param_grid,cv=n_folds,n_jobs=-1,return_train_score=False,verbose=3,scoring='f1')\n",
    "cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f960fb1",
   "metadata": {},
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d2bed0a",
   "metadata": {},
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_tuned=RandomForestClassifier(criterion='entropy', max_depth=5, max_features='sqrt',\n",
    "                       min_samples_leaf=3, n_estimators=150)\n",
    "rfc_tuned.fit(x_train,y_train)\n",
    "y_pred=rfc_tuned.predict(x_test)\n",
    "print_metrix(y_test,y_pred,'Random Forest Tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f10e9",
   "metadata": {},
   "source": [
    "### Model Interpretation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e155fbc",
   "metadata": {},
   "source": [
    "!pip install shap --quite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19931d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "X=df.drop(\"Outcome\",axis=1)\n",
    "value = shap.TreeExplainer(rfc_tuned).shap_values(x_test)\n",
    "shap.summary_plot(value,x_train,plot_type=\"bar\",feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71051563",
   "metadata": {},
   "source": [
    "### Create pipeline for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ef102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "sc = StandardScaler()\n",
    "rfc_tuned = rfc_tuned\n",
    "x_train,x_test,y_train,y_test = preprocess(df,\"Outcome\")\n",
    "steps=[(\"scaling\",sc),('rfc tuned',rfc_tuned)]\n",
    "pipeline=Pipeline(steps)\n",
    "pipeline.fit(x_train,y_train)\n",
    "y_pred = pipeline.predict(x_test)\n",
    "print_metrix(y_test,y_pred,'Pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5835ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the pipeline\n",
    "\n",
    "import pickle\n",
    "model=open('rfc.pickle','wb')\n",
    "pickle.dump(pipeline,model)\n",
    "model.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a9b03a",
   "metadata": {},
   "source": [
    "### Deployment of the pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a02c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "st.title(\"Medical Diagnostic Web App \")\n",
    "\n",
    "# Step 1 : Load the model\n",
    "model=open('rfc.pickle','rb')\n",
    "clf=pickle.load(model)\n",
    "model.close()\n",
    "\n",
    "#Step2: Get the front end user input\n",
    "pregs=st.number_input('Pregnancies',1,20,step=1)\n",
    "glucose=st.slider('Glucose',40.0,200.0,40.0)\n",
    "bp=st.slider('BloodPressure',24,122,24)\n",
    "skin=st.slider('SkinThickness',7,99,7)\n",
    "insulin=st.slider('Insulin',18.0,850.0,18.0)\n",
    "bmi=st.slider('BMI',18.0,67.0,18.0)\n",
    "dpf=st.slider('DiabetesPedigreeFunction',0.05,2.5,0.05)\n",
    "age=st.slider('Age',21,81,21)\n",
    "\n",
    "\n",
    "# Step 3: converting user input to model input\n",
    "data={'Pregnancies':pregs,\n",
    "      'Glucose':glucose,\n",
    "      'BloodPressure':bp,\n",
    "      'SkinThickness':skin,\n",
    "      'Insulin':insulin,\n",
    "       'BMI':bmi,\n",
    "      'DiabetesPedigreeFunction':dpf,\n",
    "      'Age':age}\n",
    "\n",
    "input_data=pd.DataFrame([data])\n",
    "\n",
    "#Step4 : Get the predictions\n",
    "\n",
    "preds=clf.predict(input_data)[0]\n",
    "if st.button(\"Predict\"):\n",
    "    if preds==1:\n",
    "        st.error(\"The Person has Diabetes\")\n",
    "    if preds==0:\n",
    "        st.success(\"The Person is Diabetes free\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659680f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[:]].agg(['min','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e189e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c357a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
